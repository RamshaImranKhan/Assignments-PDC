{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOOhRgWVJz7vkQWgJstECtz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fiy3Dj1qThcF","executionInfo":{"status":"ok","timestamp":1760623198365,"user_tz":-300,"elapsed":2175,"user":{"displayName":"RAMSHA KHAN","userId":"10959223629031507632"}},"outputId":"34183595-58cf-4683-efa0-23dffdcefc35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1: Memory Allocation and Initialization\n","First 5 elements of A: [0 1 2 3 4]\n","First 5 elements of B: [0 2 4 6 8]\n","Data copied to GPU\n","Step 2: Serial Execution on Default Stream\n","Kernel1 executed: C = A + B\n","Kernel2 executed: D = C * C\n","First 5 elements of D: [  0   9  36  81 144]\n","Validation check for D[4]: expected 144 got 144\n","Step 3: Parallel Execution with CUDA Streams\n","Kernel1 launched on Stream1\n","Kernel2 launched on Stream2\n","First 5 elements of streamed D: [  0   9  36  81 144]\n","Step 4: Synchronization Scenarios\n","With explicit synchronization, CPU blocked for 0.00026 seconds\n","With implicit synchronization, .get() waited automatically\n","Step 5: Thread Hierarchy Visualization\n","Configuration 1: <<<1, N>>> (1 block, N threads)\n","Configuration 2: <<<N/32, 32>>> (multiple blocks)\n","Done\n"]}],"source":["\n","import cupy as cp\n","import numpy as np\n","import time\n","\n","N = 1024\n","THREADS_PER_BLOCK = 32\n","BLOCKS_N_32 = (N // THREADS_PER_BLOCK, 1, 1)\n","THREADS_32 = (THREADS_PER_BLOCK, 1, 1)\n","\n","CUDA_KERNELS = r'''\n","extern \"C\" __global__ void kernel_indexing(int N) {\n","    int i = blockIdx.x * blockDim.x + threadIdx.x;\n","    if (i == 0 || i == N - 1 || i == N/2) {\n","        printf(\"Thread %d / %d | BlockIdx=%d | ThreadIdx=%d\\n\",\n","               i, N, blockIdx.x, threadIdx.x);\n","    }\n","    if (blockIdx.x == 0 && threadIdx.x == 0) {\n","        printf(\"Launch Metadata: GridDim=%d | BlockDim=%d\\n\",\n","               gridDim.x, blockDim.x);\n","    }\n","}\n","''';\n","\n","k_index = cp.RawKernel(CUDA_KERNELS, 'kernel_indexing')\n","\n","print(\"Step 1: Memory Allocation and Initialization\")\n","\n","A_host = np.arange(N, dtype=np.int32)\n","B_host = 2 * np.arange(N, dtype=np.int32)\n","\n","print(\"First 5 elements of A:\", A_host[:5])\n","print(\"First 5 elements of B:\", B_host[:5])\n","\n","A_device = cp.asarray(A_host)\n","B_device = cp.asarray(B_host)\n","print(\"Data copied to GPU\")\n","\n","print(\"Step 2: Serial Execution on Default Stream\")\n","\n","C_device = A_device + B_device\n","print(\"Kernel1 executed: C = A + B\")\n","\n","D_device = C_device * C_device\n","print(\"Kernel2 executed: D = C * C\")\n","\n","D_serial = D_device.get()\n","print(\"First 5 elements of D:\", D_serial[:5])\n","\n","expected = (A_host[4] + B_host[4]) ** 2\n","print(\"Validation check for D[4]: expected\", expected, \"got\", D_serial[4])\n","\n","print(\"Step 3: Parallel Execution with CUDA Streams\")\n","\n","stream1, stream2 = cp.cuda.Stream(), cp.cuda.Stream()\n","event = cp.cuda.Event()\n","D_device.fill(0)\n","\n","with stream1:\n","    C_stream = A_device + B_device\n","    stream1.record(event)\n","    print(\"Kernel1 launched on Stream1\")\n","\n","stream2.wait_event(event)\n","with stream2:\n","    D_stream = C_stream * C_stream\n","    print(\"Kernel2 launched on Stream2\")\n","\n","D_stream_host = D_stream.get(stream=stream2)\n","stream2.synchronize()\n","print(\"First 5 elements of streamed D:\", D_stream_host[:5])\n","\n","print(\"Step 4: Synchronization Scenarios\")\n","\n","start_time = time.time()\n","D_device = (A_device + B_device) * (A_device + B_device)\n","cp.cuda.Device(0).synchronize()\n","sync_time = time.time() - start_time\n","print(\"With explicit synchronization, CPU blocked for\", round(sync_time, 5), \"seconds\")\n","\n","D_device.fill(0)\n","D_device = (A_device + B_device) * (A_device + B_device)\n","time.sleep(0.001)\n","D_nosync = D_device.get()\n","print(\"With implicit synchronization, .get() waited automatically\")\n","\n","print(\"Step 5: Thread Hierarchy Visualization\")\n","\n","print(\"Configuration 1: <<<1, N>>> (1 block, N threads)\")\n","k_index((1, 1, 1), (N, 1, 1), (N,))\n","cp.cuda.Device(0).synchronize()\n","\n","print(\"Configuration 2: <<<N/32, 32>>> (multiple blocks)\")\n","k_index(BLOCKS_N_32, THREADS_32, (N,))\n","cp.cuda.Device(0).synchronize()\n","\n","print(\"Done\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"ktuRuGA_UbWk"},"execution_count":null,"outputs":[]}]}